{
    "version": "https://jsonfeed.org/version/1",
    "title": "matt williams",
    "description": "",
    "home_page_url": "https://mattwilliams-ds.github.io/gh-page",
    "feed_url": "https://mattwilliams-ds.github.io/gh-page/feed.json",
    "user_comment": "",
    "author": {
        "name": "Matt Williams"
    },
    "items": [
        {
            "id": "https://mattwilliams-ds.github.io/gh-page/pairwise-radius-clustering/",
            "url": "https://mattwilliams-ds.github.io/gh-page/pairwise-radius-clustering/",
            "title": "Pairwise Radius Clustering",
            "summary": "Concept I was recently tasked with reviewing several hundred launching girder kinematic manuals. Launching girders are large overhead cranes used to erect bridges and the kinematic manuals are step-by-step proceedures for erecting each bridge span. To economize our efforts I needed a way to group&hellip;",
            "content_html": "<p><strong>Concept</strong></p>\n<p>I was recently tasked with reviewing several hundred launching girder kinematic manuals. Launching girders are large overhead cranes used to erect bridges and the kinematic manuals are step-by-step proceedures for erecting each bridge span.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/13//lg.png\" alt=\"launching girder\" width=\"1000\" height=\"750\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/lg-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/lg-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/lg-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/lg-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/lg-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/lg-2xl.png 1920w\"></figure>\n<p>To economize our efforts I needed a way to group these manuals and thus reduce the number of sequences we had to perform a full structural analysis of.</p>\n<p>Two manuals can be considered similar if the length of the span the gantry starts at and the length of the span that the gantry launches to are similar. For this exercise, two spans are considered similar if they are within 5m in length of each other.</p>\n<p>Since both span lengths are in meters and similar spans are within 5m of each other, running the clustering algorithm with a radius of 2.5m resulted in appropriate clusters of like manuals.</p>\n<p><strong>Data</strong></p>\n<p>The data used included the length of the two span lengths of each kinematic manual as well as a label denoting which launching gantry was used to erect each span. This data was specific to the project I was working on and is not publicly available.</p>\n<p><strong>Process</strong></p>\n<ol>\n<li>Read the data into a <strong>Pandas</strong> DataFrame in <strong>Python</strong>.</li>\n<li>Separate data for each gantry type into separate DataFrames.</li>\n<li>Create a <a href=\"https://contrib.scikit-learn.org/radius_clustering/index.html\" title=\"radius clustering library\" target=\"_blank\" rel=\"noopener noreferrer\">Radius Cluster</a> model for each gantry type with a specified radius to consider.</li>\n<li>Apply clustering group numbers to each data point and export for further analysis in <strong>Excel</strong>.</li>\n<li>Use engineering judgement to further refine the groups.</li>\n</ol>\n<p><strong>Results</strong></p>\n<p>The following plot shows the 1st and 2nd span lengths for the kinematic manuals of one of the launching girders. They are colored by the assigned group number. The clustering algorithm assigned 27 groups in total though the plot is limited by the number of colors in the color scale.</p>\n<figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/13//l160_groups.png\" alt=\"kinematic manual clustering\" width=\"563\" height=\"453\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/l160_groups-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/l160_groups-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/l160_groups-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/l160_groups-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/l160_groups-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/13//responsive/l160_groups-2xl.png 1920w\"></figure>\n<p>The number of groups was further reduced using engineering judgement and drastically improved our workflow.</p>\n<p>My python code is available <a href=\"https://github.com/mattwilliams-ds/Data_Science_Projects/blob/main/radius_clustering/EM_grouping_v02.ipynb\" target=\"_blank\" rel=\"noopener noreferrer\">on github here</a>.</p>",
            "author": {
                "name": "Matt Williams"
            },
            "tags": [
                   "Engineering",
                   "All Projects"
            ],
            "date_published": "2025-11-29T11:46:41-07:00",
            "date_modified": "2025-11-29T11:49:28-07:00"
        },
        {
            "id": "https://mattwilliams-ds.github.io/gh-page/vehicle-crash-density-map/",
            "url": "https://mattwilliams-ds.github.io/gh-page/vehicle-crash-density-map/",
            "title": "Vehicle Crash Density Map",
            "summary": "Concept After being rear-ended in a car accident, I wanted to analyze which intersections in the town where the accident occurred have experienced the highest number of car accidents over the past four years. Data Colorado Department of Transportation Crash Data Process Results Here is&hellip;",
            "content_html": "<p><strong>Concept</strong></p>\n<p>After being rear-ended in a car accident, I wanted to analyze which intersections in the town where the accident occurred have experienced the highest number of car accidents over the past four years.</p>\n<p><strong>Data</strong></p>\n<p><a href=\"https://www.codot.gov/safety/traffic-safety/data-analysis/crash-data\" title=\"CDOT Crash Data\" target=\"_blank\" rel=\"noopener noreferrer\">Colorado Department of Transportation Crash Data</a></p>\n<p><strong>Process</strong></p>\n<ol>\n<li>Import crash data to a <strong>Pandas</strong> DataFrame for 2021 through 2024.</li>\n<li>Concatenate all crash data.</li>\n<li>Clean data &amp; standardizing street names.</li>\n<li>Create a single column containing both cross-streets for each accident.</li>\n<li>Use the <strong>Google Maps API</strong> to geocode all intersections.</li>\n<li>Export intersections and accident count data to a CSV &amp; import as a <strong>SQL</strong> database.</li>\n<li>Write a <a href=\"https://github.com/mattwilliams-ds/Data_Science_Projects/blob/main/longmont_accidents/longmont_crashes.sql\" title=\"SQL query\" target=\"_blank\" rel=\"noopener noreferrer\">SQL query</a> to compile a list of intersections and accident counts.</li>\n<li>Use <strong>QGIS</strong> to create a map of the intersections with the highest accident counts.</li>\n</ol>\n<p><strong>Results</strong></p>\n<p>Here is the map I created of the twenty intersections with the highest accident counts. And, yes, the intersection where my accident occured made the top twenty.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/12/Longmont_Crash_Density.png\" alt=\"Crash Density Map of Longmont, Colorado\" width=\"1166\" height=\"1078\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/12/responsive/Longmont_Crash_Density-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/12/responsive/Longmont_Crash_Density-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/12/responsive/Longmont_Crash_Density-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/12/responsive/Longmont_Crash_Density-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/12/responsive/Longmont_Crash_Density-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/12/responsive/Longmont_Crash_Density-2xl.png 1920w\"></figure>\n<p>All of my project files can be viewed <a href=\"https://github.com/mattwilliams-ds/Data_Science_Projects/tree/main/longmont_accidents\" title=\"github link\" target=\"_blank\" rel=\"noopener noreferrer\">here on github</a>.</p>",
            "author": {
                "name": "Matt Williams"
            },
            "tags": [
                   "Engineering",
                   "All Projects"
            ],
            "date_published": "2025-11-29T08:03:59-07:00",
            "date_modified": "2026-01-30T05:58:24-07:00"
        },
        {
            "id": "https://mattwilliams-ds.github.io/gh-page/sales-analytics-using-sql/",
            "url": "https://mattwilliams-ds.github.io/gh-page/sales-analytics-using-sql/",
            "title": "Sales Analytics using SQL",
            "summary": "Concept Using company sales data and SQLite, I set out to determine the following: Data Sample Sales Data on Kaggle Process Results Exploring the sales data and developing SQL queries in DB Browser was very straight forward. The most challenging query invovled calculating the average&hellip;",
            "content_html": "<p><strong>Concept</strong></p>\n<p>Using company sales data and SQLite, I set out to determine the following:</p>\n<ul>\n<li>What are best and worst performing products and product lines</li>\n<li>Determine where the company's products are selling the best</li>\n<li>Identifying the company's best customers</li>\n<li>Quantify company performance over time</li>\n</ul>\n<p><strong>Data</strong></p>\n<p><a href=\"https://www.kaggle.com/datasets/kyanyoga/sample-sales-data\" target=\"_blank\" rel=\"noopener noreferrer\">Sample Sales Data on Kaggle</a></p>\n<p><strong>Process</strong></p>\n<ol>\n<li>Create a database from the CSV sales data file using DB Browser.</li>\n<li>Craft SQLite queries using aggregate functions, subquerries, and joins to answer eight business intelligence questions related to the insights listed above.</li>\n<li>Draw actionable insights from the query results.</li>\n</ol>\n<p><strong>Results</strong></p>\n<p>Exploring the sales data and developing SQL queries in DB Browser was very straight forward. The most challenging query invovled calculating the average sales by month for all data in the dataset.</p>\n<p>The challenge here was the two and a half years of data so some months are averaged over three instances and other over two months. I was able to next two levels of sub queries to determine how many of each month is in the dataset and then set out to divide the total sales by the number of months.</p>\n<p><a href=\"https://github.com/mattwilliams-ds/SQL-projects/blob/7a73b0d6894b31c932448e6a9462318bc6d0f70a/Sales_Analytics/sales_project_v02.sql\" target=\"_blank\" rel=\"noopener noreferrer\">Click here to see the entire set of queries</a></p>\n<p>Here is the final query:</p>\n<p> </p>\n<div><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/11/Screenshot-from-2025-03-04-18-25-19.png\" alt=\"SQL Query\" width=\"926\" height=\"771\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-25-19-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-25-19-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-25-19-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-25-19-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-25-19-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-25-19-2xl.png 1920w\"></figure></div>\n<div> </div>\n<div>One great feature of DB Browser is the ability to create plots from your query results right there in the program. There aren't many customization options but for exploring data, its more than adequate. Here's a plot of the average sales by month from the above query.</div>\n<div> </div>\n<div><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/11/Screenshot-from-2025-03-04-18-27-31.png\" alt=\"average sales by month\" width=\"909\" height=\"729\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-27-31-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-27-31-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-27-31-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-27-31-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-27-31-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/11/responsive/Screenshot-from-2025-03-04-18-27-31-2xl.png 1920w\"></figure></div>",
            "author": {
                "name": "Matt Williams"
            },
            "tags": [
                   "Business Intelligence",
                   "All Projects"
            ],
            "date_published": "2025-03-02T06:51:11-07:00",
            "date_modified": "2025-11-29T08:03:40-07:00"
        },
        {
            "id": "https://mattwilliams-ds.github.io/gh-page/vulnerability-study-of-coastal-bridges/",
            "url": "https://mattwilliams-ds.github.io/gh-page/vulnerability-study-of-coastal-bridges/",
            "title": "Vulnerability Study of Coastal Bridges",
            "summary": "Concept This project sought to develop a system of rating coastal counties in the U.S. by the vulnerability of their bridge infrastructure. The scoring system developed awards one level or risk for each of the following factors: By identifying coastal counties with at risk bridge&hellip;",
            "content_html": "<p><strong>Concept</strong></p>\n<p>This project sought to develop a system of rating coastal counties in the U.S. by the vulnerability of their bridge infrastructure. The scoring system developed awards one level or risk for each of the following factors:</p>\n<figure class=\"post__image post__image--right\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/10/median_bridge_age-2.png\" alt=\"Median Bridge Age\" width=\"400\" height=\"226\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/median_bridge_age-2-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/median_bridge_age-2-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/median_bridge_age-2-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/median_bridge_age-2-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/median_bridge_age-2-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/median_bridge_age-2-2xl.png 1920w\"></figure>Bridge population is aging</p>\n<ul>\n<li>Bridge Ratings are in decline</li>\n<li>County population is increasing (putting more demand on the bridges)</li>\n<li>Frequency of storm events that could impact structure health are increasing</li>\n</ul>\n<p>By identifying coastal counties with at risk bridge structures, Federal and state transportation agencies can have a clear and concise indicator of where future infrastructure investments may be needed.</p>\n<p><strong>Data</strong></p>\n<ol>\n<li>FHWA's <a href=\"https://www.fhwa.dot.gov/bridge/nbi.cfm\" title=\"FHWA National Bridge Inventory\" target=\"_blank\" rel=\"noopener noreferrer\">National Bridge Inventory</a></li>\n<li><a href=\"https://www.census.gov/data/datasets/time-series/demo/popest/2020s-counties-total.html\" title=\"US Census Data\" target=\"_blank\" rel=\"noopener noreferrer\">US Census data</a></li>\n<li>NCEI <a href=\"https://www.ncdc.noaa.gov/stormevents/ftp.jsp\" title=\"Storm Events Database\" target=\"_blank\" rel=\"noopener noreferrer\">Storm Events Database</a></li>\n</ol>\n<p><strong>Process</strong></p>\n<ol>\n<li>Clean &amp; process Bridge Inventory data in <strong>Python</strong>, filtering out non-coastal counties. Attributes of interest included bridge ratings, year of construction, and geolocation data.</li>\n<li>Determine bridge age for all structures in cleaned dataset.</li>\n<li>Calculate average bridge rating by taking the geometric mean of the ratings for each bridge component.</li>\n<li>Calculate the rate of change of the average bridge ratings by county using a <strong>linear regressor</strong> and taking the slope as the rate of change.</li>\n<li>Clean &amp; process US Census population data in <strong>Python</strong>.</li>\n<li>Calculate rate of population change over a ten year period.</li>\n<li>Clean &amp; process NCEI storm event counts, filtering out event types that are not likely to impact bridge condition (fog for example).</li>\n<li>Calculate the rate of change of storm event occurances over time using a <strong>Poisson regressor</strong> and filtering out counties with that are not significant (p-values less than 0.05).</li>\n<li>Combine average bridge age, change in average bridge rating, county population, and rate of change of storm events for each county into a single <strong>Pandas</strong> dataframe.</li>\n<li>Tally risk factors for each county and export data.</li>\n<li>Import county risk tally data into <strong>QGIS</strong> and create <strong>chloropleth maps</strong> to document findings.</li>\n</ol>\n<p><strong>Results</strong></p>\n<p>This study successfully rated each coastal county in the US. Ten counties were found to have a vulnerability score of four meaning that they have all for risk factors; aging infrastructure, declining infrastructure, increasing population, and increasing storm events. The following chloropleth map shows the rating for each county.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/10/county_vulnerability_scores.png\" alt=\"County Vulnerability Map\" width=\"1546\" height=\"891\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/county_vulnerability_scores-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/county_vulnerability_scores-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/county_vulnerability_scores-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/county_vulnerability_scores-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/county_vulnerability_scores-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/10/responsive/county_vulnerability_scores-2xl.png 1920w\"><figcaption><em>Vulnerability Scores of Coastal U.S. Counties</em></figcaption></figure>\n<p>The 10 counties with a vulnerability score of four are:</p>\n<table style=\"border-collapse: collapse; width: 100%; height: 241.75px; border-style: none;\" border=\"0\">\n<tbody>\n<tr style=\"height: 48.35px;\">\n<td style=\"width: 49.943%; height: 48.35px;\">San Diego County, California</td>\n<td style=\"width: 49.943%; height: 48.35px;\">Barnstable County, Massachusetts</td>\n</tr>\n<tr style=\"height: 48.35px;\">\n<td style=\"width: 49.943%; height: 48.35px;\">Santa Cruz County, California</td>\n<td style=\"width: 49.943%; height: 48.35px;\">Douglas County, Oregon</td>\n</tr>\n<tr style=\"height: 48.35px;\">\n<td style=\"width: 49.943%; height: 48.35px;\">Fairfield County, Connecticut</td>\n<td style=\"width: 49.943%; height: 48.35px;\">Nueces County, Texas</td>\n</tr>\n<tr style=\"height: 48.35px;\">\n<td style=\"width: 49.943%; height: 48.35px;\">Escambia County, Florida</td>\n<td style=\"width: 49.943%; height: 48.35px;\">James City County, Virginia</td>\n</tr>\n<tr style=\"height: 48.35px;\">\n<td style=\"width: 49.943%; height: 48.35px;\">Lee County, Florida</td>\n<td style=\"width: 49.943%; height: 48.35px;\">Snohomish County, Washington</td>\n</tr>\n</tbody>\n</table>\n<p>The collection of scripts developed in the course of this project are available <a href=\"https://github.com/mattwilliams-ds/coastal_bridges\" title=\"Bridge Vulnerability Study\" target=\"_blank\" rel=\"noopener noreferrer\">here on github</a>. A full report on the project is also <a href=\"https://drive.google.com/file/d/1Co_J1ejcm1PjDSXzqr7fspOCN_hlEUKl/view?usp=drive_link\" title=\"Bridge Vulnerability Report\" target=\"_blank\" rel=\"noopener noreferrer\">available here</a>.</p>",
            "author": {
                "name": "Matt Williams"
            },
            "tags": [
                   "Engineering",
                   "All Projects"
            ],
            "date_published": "2025-01-19T13:13:22-07:00",
            "date_modified": "2025-03-07T12:05:55-07:00"
        },
        {
            "id": "https://mattwilliams-ds.github.io/gh-page/patterns-in-structurally-deficient-bridges/",
            "url": "https://mattwilliams-ds.github.io/gh-page/patterns-in-structurally-deficient-bridges/",
            "title": "Patterns in Structurally Deficient Bridges",
            "summary": "Concept The impetus of this project was to identify common traits among structurally deficient bridges in the United States. To do this, FHWA's National Bridge Inventory was analyzed with the FPGrowth algorithm which is commonly used for finding patterns in retail shopping carts. Applying FPGrowth&hellip;",
            "content_html": "<p><strong>Concept</strong></p>\n<p>The impetus of this project was to identify common traits among structurally deficient bridges in the United States. To do this, FHWA's National Bridge Inventory was analyzed with the FPGrowth algorithm which is commonly used for finding patterns in retail shopping carts.</p>\n<p>Applying FPGrowth to the bridge inventory required numeric ratings to be categorized as the FPGrowth algorithm works by making associations between text string values present for each record. Several other attributes were also categorized to make more generic rules.</p>\n<p><strong>Data</strong></p>\n<ul>\n<li>FHWA's <a href=\"https://www.fhwa.dot.gov/bridge/nbi.cfm\" title=\"FHWA National Bridge Inventory\" target=\"_blank\" rel=\"noopener noreferrer\">National Bridge Inventory</a></li>\n</ul>\n<p><strong>Process</strong></p>\n<ol>\n<li>Read NBI data into a <strong>PySpark</strong> dataframe.</li>\n<li>Clean the data by removing bridges with missing or misformatted ratings as well as bridges that are not structurally deficient.</li>\n<li>Remove culverts from the data set as these have a different structural system than conventional bridges.</li>\n<li>Select data using PySpark <strong>SQL</strong> Functions and create visualizations using <strong>Matplotlib</strong>.</li>\n<li>Categorize bridge age, regional location, structure type, and structural system ratings (deck, superstructure, substructure) as follows:<figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/9/bridge_rating_categorization.png\" alt=\"Bridge Rating Categorization\" width=\"363\" height=\"240\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/bridge_rating_categorization-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/bridge_rating_categorization-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/bridge_rating_categorization-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/bridge_rating_categorization-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/bridge_rating_categorization-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/bridge_rating_categorization-2xl.png 1920w\"></figure></li>\n<li>Use the <strong>FPGrowth</strong> frequent pattern algorithm to develop association rules.</li>\n<li>Review the rules and their support &amp; confidence statistical parameters to determine which are worth highlighting.</li>\n<li>Perform additional statistical analyses to identify commonalities common shortcomings of deficient bridges.</li>\n</ol>\n<p><strong>Results</strong></p>\n<p>The most relevant and interesting rules found in the set of structurally deficient bridges are as follows:</p>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\">\n<tbody>\n<tr>\n<td class=\"align-center\" style=\"width: 10.1255%;\"><strong>Rule</strong></td>\n<td class=\"align-center\" style=\"width: 29.093%;\"><strong>Antecedent</strong></td>\n<td class=\"align-center\" style=\"width: 27.6669%;\"><strong>Consequent</strong></td>\n<td class=\"align-center\" style=\"width: 15.2596%;\"><strong>Support</strong></td>\n<td class=\"align-center\" style=\"width: 17.8266%;\"><strong>Confidence</strong></td>\n</tr>\n<tr>\n<td class=\"align-center\" style=\"width: 10.1255%;\">1</td>\n<td style=\"width: 29.093%;\">Deck in Good Condition</td>\n<td style=\"width: 27.6669%;\">Substructure in Poor Condition</td>\n<td class=\"align-center\" style=\"width: 15.2596%;\">0.73</td>\n<td class=\"align-center\" style=\"width: 17.8266%;\">0.43</td>\n</tr>\n<tr>\n<td class=\"align-center\" style=\"width: 10.1255%;\">2</td>\n<td style=\"width: 29.093%;\">Superstructure in Good Condition</td>\n<td style=\"width: 27.6669%;\">Substructure in Poor Condition</td>\n<td class=\"align-center\" style=\"width: 15.2596%;\">0.77</td>\n<td class=\"align-center\" style=\"width: 17.8266%;\">0.40</td>\n</tr>\n<tr>\n<td class=\"align-center\" style=\"width: 10.1255%;\">3</td>\n<td style=\"width: 29.093%;\">Deck is cast-in-place concrete</td>\n<td style=\"width: 27.6669%;\">Deck is in poor condition</td>\n<td class=\"align-center\" style=\"width: 15.2596%;\">0.44</td>\n<td class=\"align-center\" style=\"width: 17.8266%;\">0.24</td>\n</tr>\n<tr>\n<td class=\"align-center\" style=\"width: 10.1255%;\">4</td>\n<td style=\"width: 29.093%;\">Girder bridge type + 1-2 spans long</td>\n<td style=\"width: 27.6669%;\">Superstructure is a steel girder type</td>\n<td class=\"align-center\" style=\"width: 15.2596%;\">0.75</td>\n<td class=\"align-center\" style=\"width: 17.8266%;\">0.25</td>\n</tr>\n</tbody>\n</table>\n<p>To give you an idea of what all of this is saying, let's break down the first rule. Starting with the confidence, the rule is telling us that \"out of all structurally deficient bridges that have a deck in good condition, 73% of them have a substructure that is in poor condition\". The confidence tell us that \"43% of all structurally deficient bridges have both a deck that is in good condition and a substructure that is in poor condition\".</p>\n<p>Note that rules one and two both speak to the substructure being in poor condition. This was one of the major findings of this project. The bridge substructure is the most common structural element in poor condition among structurally deficient bridges. This was confirmed by looking at the percentage of structurally deficient systems in the set of deficient bridges.</p>\n<figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/9/poor_structural_elements-2.png\" alt=\"Structural systems in poor conditions.\" width=\"744\" height=\"410\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/poor_structural_elements-2-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/poor_structural_elements-2-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/poor_structural_elements-2-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/poor_structural_elements-2-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/poor_structural_elements-2-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/9/responsive/poor_structural_elements-2-2xl.png 1920w\"></figure>\n<p>Here is a video presentation I made of this project. You can also have a look through my <a href=\"https://colab.research.google.com/drive/1s6ki2vER671L1qWRRjx5AuH6KnHHPdXa?usp=drive_link\" title=\"Colab Notebook\" target=\"_blank\" rel=\"noopener noreferrer\">Colab Notebook</a>.</p>\n<figure class=\"post__video\"><iframe loading=\"lazy\" width=\"560\" height=\"314\" src=\"https://www.youtube.com/embed/vI6ARHd0JPk?si=QFAVg02O1kB01pre\" allowfullscreen=\"allowfullscreen\" data-mce-fragment=\"1\"></iframe></figure>\n<p> </p>",
            "author": {
                "name": "Matt Williams"
            },
            "tags": [
                   "Engineering",
                   "All Projects"
            ],
            "date_published": "2025-01-11T13:50:40-07:00",
            "date_modified": "2025-03-07T12:06:11-07:00"
        },
        {
            "id": "https://mattwilliams-ds.github.io/gh-page/predicting-concrete-strength/",
            "url": "https://mattwilliams-ds.github.io/gh-page/predicting-concrete-strength/",
            "title": "Predicting Concrete Strength",
            "summary": "Concept This project is an extension to my project titled Effects of Concrete Mix Design &amp; Aging on Strength. Here, I sought to develop a machine learning model that could predict the 28 day concrete breaking strength based on the sample's mix design. I used&hellip;",
            "content_html": "<p><strong>Concept</strong></p>\n<p>This project is an extension to my project titled <a href=\"https://mattwilliams-ds.github.io/gh-page/effects-of-concrete-mix-design-and-aging-on-strength/\" title=\"effects of concrete mix on strength\" target=\"_blank\" rel=\"noopener noreferrer\">Effects of Concrete Mix Design &amp; Aging on Strength</a>. Here, I sought to develop a machine learning model that could predict the 28 day concrete breaking strength based on the sample's mix design. I used several regression models predict concete strengths. I then tuned the best performing model to maximize model results.</p>\n<p><strong>Data</strong></p>\n<p><a href=\"https://archive.ics.uci.edu/dataset/165/concrete+compressive+strength\" title=\"UC Irvine concrete compressive data\" target=\"_blank\" rel=\"noopener noreferrer\">Concrete Compressive Strength [creative commons] from UC Irvine</a></p>\n<p><strong>Process</strong></p>\n<ol>\n<li>Read data into a <strong>Pandas</strong> dataframe.</li>\n<li>Look for &amp; remove records with missing data.</li>\n<li>Explore the relationship of the mix ingredients using a <strong>seaborn</strong> correlation matrix and pair plots.</li>\n<li>Isolate records for 28 day breaks.</li>\n<li>Split the data 85% for training and 15% for testing.</li>\n<li>Train &amp; test several <strong>scikit-learn</strong> regression models including decision trees, random forests, kNN, multi-layer perceptron, and adaBoost.</li>\n<li>Tune best performing model.</li>\n</ol>\n<p><strong>Results</strong></p>\n<p>The correlation matrix (shown here) highlighted several interesting relationships. Most notably is the negative correlation between water and the superplasticizer additive. Second to that, the cement content and concrete strength showed a positive correlation.</p>\n<figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/8/Screenshot-from-2025-01-05-09-50-15.png\" alt=\"seaborn correlation matrix plot\" width=\"600\" height=\"492\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/Screenshot-from-2025-01-05-09-50-15-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/Screenshot-from-2025-01-05-09-50-15-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/Screenshot-from-2025-01-05-09-50-15-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/Screenshot-from-2025-01-05-09-50-15-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/Screenshot-from-2025-01-05-09-50-15-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/Screenshot-from-2025-01-05-09-50-15-2xl.png 1920w\"></figure>\n<p>After training and testing each of the machine learning algorithms, I found that the random forest model performed the best with a model score of 0.839. With further tuning of the model I was able to increase the model performance to 0.891. This was accomplished through feature selection, increasing the depth of the decision trees making up the forest, and increasing the number of trees in the forest.</p>\n<p>The following diagram plots the actual breaking strength versus the predicted breaking strength of the test data.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/8/predicting_conc_strength.png\" alt=\"Actual vs Predicted Concrete Strength\" width=\"724\" height=\"738\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/predicting_conc_strength-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/predicting_conc_strength-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/predicting_conc_strength-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/predicting_conc_strength-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/predicting_conc_strength-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/8/responsive/predicting_conc_strength-2xl.png 1920w\"></figure>\n<p>Check out the entire project <a href=\"https://github.com/mattwilliams-ds/Data_Science_Projects/blob/main/predicting_concrete_strength/Predicting_Concrete_Strength.ipynb\" title=\"predicting concrete strength notebook\" target=\"_blank\" rel=\"noopener noreferrer\">Jupyter Notebook</a> for more information.</p>",
            "author": {
                "name": "Matt Williams"
            },
            "tags": [
                   "Engineering",
                   "All Projects"
            ],
            "date_published": "2025-01-05T09:25:27-07:00",
            "date_modified": "2025-11-29T11:19:31-07:00"
        },
        {
            "id": "https://mattwilliams-ds.github.io/gh-page/effects-of-concrete-mix-design-and-aging-on-strength/",
            "url": "https://mattwilliams-ds.github.io/gh-page/effects-of-concrete-mix-design-and-aging-on-strength/",
            "title": "Effects of Concrete Mix Design &amp; Aging on Strength",
            "summary": "Concept Construction industries the world over favor different strength concretes for different applications. This project seeks to discern patterns in concrete mix component concentrations for low, medium, and high strength concretes. The dataset includes breaking strengths for just over 1,000 samples, their mix design, and the&hellip;",
            "content_html": "<p><strong>Concept</strong></p>\n<p>Construction industries the world over favor different strength concretes for different applications. This project seeks to discern patterns in concrete mix component concentrations for low, medium, and high strength concretes. The dataset includes breaking strengths for just over 1,000 samples, their mix design, and the age at which the sample was tested.</p>\n<p>While the dataset contains samples broken at different ages, the standard age for concrete strengths is 28 days. This is the strength at which most concrete structures are designed with. Concrete strength does increase over time beyond 28 days. This increase, however, is generally not counted on by structural engineers and is why this project uses only the breaks made at 28 days.</p>\n<p><strong>Data</strong></p>\n<p><a href=\"https://archive.ics.uci.edu/dataset/165/concrete+compressive+strength\" title=\"UC Irvine concrete compressive data\" target=\"_blank\" rel=\"noopener noreferrer\">Concrete Compressive Strength [creative commons] from UC Irvine</a></p>\n<p><strong>Process</strong></p>\n<ol>\n<li>Read csv data into a <strong>Pandas</strong> dataframe.</li>\n<li>Isolate 28 day breaking strengths.</li>\n<li>Classify 28 day records as having high, medium, or low strength.</li>\n<li>Using <strong>Seaborn</strong>, create a series of box plots for each mix ingredient for each breaking strength classification.</li>\n<li>Review box plots for trends in mix concentrations across the three breaking strength classes.</li>\n</ol>\n<p><strong>Results</strong></p>\n<p>Below are the box plots showing the ranges of mix component concentration from low strength to high strength concrete strengths, all at 28 days.</p>\n<figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/7//Screenshot-from-2025-01-04-09-07-03.png\" alt=\"Box Plots of Concrete Mix Designs\" width=\"1000\" height=\"428\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-2xl.png 1920w\"></figure>\n<p>While there is a lot of information in the box plots above it is the level of detail a structural engineer would like to see.  Going by component, the cement content increases with strength. This makes sense as cement is the binding agent that holds the aggregates together. As the cement content increases it displaces and thus reduces the aggregate content. Finally, the water content descreases slightly while superplasticizers increased. This too makes sense as superplasticizers are used to reduce the amount of water in the mix while maintaining the ability to work and consolidate the concrete.</p>\n<p>The entire project can be viewed in this <a href=\"https://drive.google.com/file/d/1gwA8R5vjOfh__89Og_c6CyTE0Oba2PLv/view?usp=sharing\" target=\"_blank\" rel=\"noopener noreferrer\">Colab Notebook</a>. It also includes some additional analysis to understand strength gains after 28 days as well. The study found that, on average, concrete strength increases by 21% from day 28 to day 365. Again, this is not generally relied upon in design but is useful to know as it provides an additional factor of safety on the design.</p>",
            "author": {
                "name": "Matt Williams"
            },
            "tags": [
                   "Engineering",
                   "All Projects"
            ],
            "date_published": "2025-01-04T09:08:24-07:00",
            "date_modified": "2025-03-07T12:06:39-07:00"
        },
        {
            "id": "https://mattwilliams-ds.github.io/gh-page/tornadoes-in-tableau/",
            "url": "https://mattwilliams-ds.github.io/gh-page/tornadoes-in-tableau/",
            "title": "Tornadoes in Tableau",
            "summary": "Concept This project was done as part of a data visualization class. My goal with this project was to create dashboards and visualizations in Tableau to show the recent history and impact of tornadoes in the United States. Data NOAA's Storm Events Database Process Results&hellip;",
            "content_html": "<p><strong>Concept</strong></p>\n<p>This project was done as part of a data visualization class. My goal with this project was to create dashboards and visualizations in Tableau to show the recent history and impact of tornadoes in the United States.</p>\n<p><strong>Data</strong></p>\n<p><a href=\"https://www.ncdc.noaa.gov/stormevents/\" title=\"NOAA Storm Events Database\" target=\"_blank\" rel=\"noopener noreferrer\">NOAA's Storm Events Database</a></p>\n<p><strong>Process</strong></p>\n<ol>\n<li>Reduce storm data to only tornado events.</li>\n<li>Clean tornado event data in a <strong>spreadsheet</strong>.</li>\n<li>Consolidate storm data to a single event (one storm may be represented as multiple events in the database as it traverses county boundaries)</li>\n<li>Develop data visualizations in <strong>Tableau</strong>.</li>\n</ol>\n<p><strong>Results</strong></p>\n<p>This project covers a lot of ground and to communicate all of that several visualizations have been created in Tableau, including a dashboard with a map of all of the tornadoes in this study. Below is a demonstration of my Tableau dashboard and interactive data visualizations.</p>\n<figure class=\"post__video\"><iframe loading=\"lazy\" width=\"560\" height=\"314\" src=\"https://www.youtube.com/embed/R4Rs-IW-sno\" allowfullscreen=\"allowfullscreen\" data-mce-fragment=\"1\"></iframe></figure>",
            "author": {
                "name": "Matt Williams"
            },
            "tags": [
                   "All Projects"
            ],
            "date_published": "2025-01-03T07:00:08-07:00",
            "date_modified": "2025-01-04T14:29:31-07:00"
        },
        {
            "id": "https://mattwilliams-ds.github.io/gh-page/wireless-sensor-network/",
            "url": "https://mattwilliams-ds.github.io/gh-page/wireless-sensor-network/",
            "title": "Wireless Sensor Network",
            "summary": "Concept An Arduino Uno was used to run a sensor for collecting ambient temperature and humidty readings as well. This data was also output to a serial port that fed into a laptop. Hardware Process Resuts This sensor network developed for this project worked as&hellip;",
            "content_html": "<p><strong>Concept</strong></p>\n<figure class=\"post__image post__image--right\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/5/wireless_sensor_network.png\" alt=\"\" width=\"550\" height=\"413\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-2xl.png 1920w\"></figure>The purpose of this project was to develop a three node wireless sensor network with an end node, router, and coordinator. Soil moisture sensors were attached to the end node and router. The data flows from the end node to the router and then from the router to the coordinator. The coordinator would then write all data to a serial port where the laptop would listen and record the incoming data.</p>\n<p>An Arduino Uno was used to run a sensor for collecting ambient temperature and humidty readings as well. This data was also output to a serial port that fed into a laptop.</p>\n<p><strong>Hardware</strong></p>\n<ol>\n<li>DIGI XBee3 Zigbee Radio Development Boards</li>\n<li>Soil Moisture Sensors</li>\n<li>Ardiuno Uno</li>\n<li>DHT11 Temperature &amp; Humidity Sensor</li>\n</ol>\n<p><strong>Process</strong></p>\n<ol>\n<li>Develop <strong>MicroPython</strong> scripts to establish communication &amp; run sensor data collection on the XBee3 radios.</li>\n<li>Develop an <strong>Arduino</strong> script to collect ambient temperature &amp; humidity readings.</li>\n<li>Develop a <strong>Python</strong> program that listens to local laptop ports for incoming data from the XBee3 coordinator and the Arduino Uno.</li>\n<li>Record all data on the laptop to a CSV file for post processing.</li>\n</ol>\n<p><strong>Resuts</strong></p>\n<p>This sensor network developed for this project worked as intended. Using try/except clauses I was able to make the network self-healing. Whenever a node dropped off the network, it would restart the communication protocol to locate the node it is supposed to report to. The MicroPython, Arduino, and serial listening scripts are <a href=\"https://github.com/mattwilliams-ds/sensor-network\" target=\"_blank\" rel=\"noopener noreferrer\">available on Github here</a>. Also, check out a demonstration of the network below.</p>\n<figure class=\"post__video\"><iframe loading=\"lazy\" width=\"560\" height=\"314\" src=\"https://www.youtube.com/embed/Yaj0-c3g5m0\" allowfullscreen=\"allowfullscreen\" data-mce-fragment=\"1\"></iframe></figure>",
            "author": {
                "name": "Matt Williams"
            },
            "tags": [
                   "All Projects"
            ],
            "date_published": "2025-01-01T11:36:40-07:00",
            "date_modified": "2025-01-04T22:44:48-07:00"
        },
        {
            "id": "https://mattwilliams-ds.github.io/gh-page/exoplanets-and-space-telescopes/",
            "url": "https://mattwilliams-ds.github.io/gh-page/exoplanets-and-space-telescopes/",
            "title": "Exoplanets &amp; Space Telescopes",
            "summary": "Concept This was an exploratory project that sought to synthesize the search for exoplanets by looking at the planets discovered, their size, and their distance from earth as well as the telescope facilities used to search for exoplanets. The project involves performing statistical analyses on&hellip;",
            "content_html": "<p><strong>Concept</strong></p>\n<p>This was an exploratory project that sought to synthesize the search for exoplanets by looking at the planets discovered, their size, and their distance from earth as well as the telescope facilities used to search for exoplanets. The project involves performing statistical analyses on the planet data as well as using regular expressions to process text descriptions of the telescopes to discern their size.</p>\n<p><strong>Data</strong></p>\n<ul>\n<li>Nasa's <a href=\"https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&amp;config=PS\" title=\"Nasa Exoplanet Archive\" target=\"_blank\" rel=\"noopener noreferrer\">Exoplanet Archive</a></li>\n</ul>\n<p><strong>Process</strong></p>\n<ol>\n<li>Clean &amp; prepare data in <strong>Python</strong> using <strong>pandas</strong>.</li>\n<li>Create a histogram of exoplanet discoveries per year with <strong>Matplotlib</strong></li>\n<li>Analyze discoveries by method and discoveries by telescope.</li>\n<li>Use <strong>RegEx</strong> expression on telescope descriptions to discern the smallest &amp; largest telescopes.</li>\n<li>Create scatter plot of planet size by year discovered.</li>\n<li>Visualize planet distance from earth by year discovered.</li>\n</ol>\n<p><strong>Results</strong></p>\n<p>Through the course of this project, I found that the Kepler telescope is responsible for the vast majority of exoplanet discoveries. K2 is a second deployment of the Kepler telescope, making it the most productive facility.</p>\n<figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://mattwilliams-ds.github.io/gh-page/media/posts/4/telescopes.png\" alt=\"Exoplanet Discoveries by Facility\" width=\"650\" height=\"357\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-2xl.png 1920w\"></figure>\n<p>The telescopes used to look for exoplanets have a staggaring range of focal lengths with the smallest being the KELT 80mm telescope and the largest being the 305m Arecibo telescope (no longer in service).</p>\n<p>Check out the entire project in my <a href=\"https://www.kaggle.com/code/mattwilliamsds/the-search-for-exoplanets\" title=\"exoplanet notebook\" target=\"_blank\" rel=\"noopener noreferrer\">kaggle notebook</a>.</p>",
            "author": {
                "name": "Matt Williams"
            },
            "tags": [
                   "All Projects"
            ],
            "date_published": "2025-01-01T08:03:59-07:00",
            "date_modified": "2025-01-01T11:26:57-07:00"
        }
    ]
}
