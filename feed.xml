<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>matt williams</title>
    <link href="https://mattwilliams-ds.github.io/gh-page/feed.xml" rel="self" />
    <link href="https://mattwilliams-ds.github.io/gh-page" />
    <updated>2025-01-04T14:29:31-07:00</updated>
    <author>
        <name>Matt Williams</name>
    </author>
    <id>https://mattwilliams-ds.github.io/gh-page</id>

    <entry>
        <title>Effects of Concrete Mix Design &amp; Aging on Strength</title>
        <author>
            <name>Matt Williams</name>
        </author>
        <link href="https://mattwilliams-ds.github.io/gh-page/effects-of-concrete-mix-design-and-aging-on-strength/"/>
        <id>https://mattwilliams-ds.github.io/gh-page/effects-of-concrete-mix-design-and-aging-on-strength/</id>
            <category term="Projects"/>

        <updated>2025-01-04T09:08:24-07:00</updated>
            <summary>
                <![CDATA[
                    Concept Construction industries the world over favor different strength concretes for different applications. This project seeks to discern patterns in concrete mix component concentrations for low, medium, and high strength concretes. The dataset includes breaking strengths for just over 1,000 samples, their mix design, and the&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p><strong>Concept</strong></p>
<p>Construction industries the world over favor different strength concretes for different applications. This project seeks to discern patterns in concrete mix component concentrations for low, medium, and high strength concretes. The dataset includes breaking strengths for just over 1,000 samples, their mix design, and the age at which the sample was tested.</p>
<p>While the dataset contains samples broken at different ages, the standard age for concrete strengths is 28 days. This is the strength at which most concrete structures are designed with. Concrete strength does increase over time beyond 28 days. This increase, however, is generally not counted on by structural engineers and is why this project uses only the breaks made at 28 days.</p>
<p><strong>Data</strong></p>
<p><a href="https://archive.ics.uci.edu/dataset/165/concrete+compressive+strength" title="UC Irvine concrete compressive data" target="_blank" rel="noopener noreferrer">Concrete Compressive Strength [creative commons] from UC Irvine</a></p>
<p><strong>Process</strong></p>
<ol>
<li>Read csv data into a <strong>Pandas</strong> dataframe.</li>
<li>Isolate 28 day breaking strengths.</li>
<li>Classify 28 day records as having high, medium, or low strength.</li>
<li>Using <strong>Seaborn</strong>, create a series of box plots for each mix ingredient for each breaking strength classification.</li>
<li>Review box plots for trends in mix concentrations across the three breaking strength classes.</li>
</ol>
<p><strong>Results</strong></p>
<p>Below are the box plots showing the ranges of mix component concentration from low strength to high strength concrete strengths, all at 28 days.</p>
<figure class="post__image post__image--center"><img loading="lazy"  src="https://mattwilliams-ds.github.io/gh-page/media/posts/7//Screenshot-from-2025-01-04-09-07-03.png" alt="Box Plots of Concrete Mix Designs" width="1000" height="428" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/7//responsive/Screenshot-from-2025-01-04-09-07-03-2xl.png 1920w"></figure>
<p>While there is a lot of information in the box plots above it is the level of detail a structural engineer would like to see.  Going by component, the cement content increases with strength. This makes sense as cement is the binding agent that holds the aggregates together. As the cement content increases it displaces and thus reduces the aggregate content. Finally, the water content descreases slightly while superplasticizers increased. This too makes sense as superplasticizers are used to reduce the amount of water in the mix while maintaining the ability to work and consolidate the concrete.</p>
<p>The entire project can be viewed in this <a href="https://drive.google.com/file/d/1gwA8R5vjOfh__89Og_c6CyTE0Oba2PLv/view?usp=sharing" target="_blank" rel="noopener noreferrer">Colab Notebook</a>. It also includes some additional analysis to understand strength gains after 28 days as well. The study found that, on average, concrete strength increases by 21% from day 28 to day 365. Again, this is not generally relied upon in design but is useful to know as it provides an additional factor of safety on the design.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Tornadoes in Tableau</title>
        <author>
            <name>Matt Williams</name>
        </author>
        <link href="https://mattwilliams-ds.github.io/gh-page/tornadoes-in-tableau/"/>
        <id>https://mattwilliams-ds.github.io/gh-page/tornadoes-in-tableau/</id>
            <category term="Projects"/>

        <updated>2025-01-03T07:00:08-07:00</updated>
            <summary>
                <![CDATA[
                    Concept This project was done as part of a data visualization class. My goal with this project was to create dashboards and visualizations in Tableau to show the recent history and impact of tornadoes in the United States. Data NOAA's Storm Events Database Process Results&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p><strong>Concept</strong></p>
<p>This project was done as part of a data visualization class. My goal with this project was to create dashboards and visualizations in Tableau to show the recent history and impact of tornadoes in the United States.</p>
<p><strong>Data</strong></p>
<p><a href="https://www.ncdc.noaa.gov/stormevents/" title="NOAA Storm Events Database" target="_blank" rel="noopener noreferrer">NOAA's Storm Events Database</a></p>
<p><strong>Process</strong></p>
<ol>
<li>Reduce storm data to only tornado events.</li>
<li>Clean tornado event data in a <strong>spreadsheet</strong>.</li>
<li>Consolidate storm data to a single event (one storm may be represented as multiple events in the database as it traverses county boundaries)</li>
<li>Develop data visualizations in <strong>Tableau</strong>.</li>
</ol>
<p><strong>Results</strong></p>
<p>This project covers a lot of ground and to communicate all of that several visualizations have been created in Tableau, including a dashboard with a map of all of the tornadoes in this study. Below is a demonstration of my Tableau dashboard and interactive data visualizations.</p>
<figure class="post__video"><iframe loading="lazy" width="560" height="314" src="https://www.youtube.com/embed/R4Rs-IW-sno" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></figure>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Wireless Sensor Network</title>
        <author>
            <name>Matt Williams</name>
        </author>
        <link href="https://mattwilliams-ds.github.io/gh-page/wireless-sensor-network/"/>
        <id>https://mattwilliams-ds.github.io/gh-page/wireless-sensor-network/</id>
            <category term="Projects"/>

        <updated>2025-01-01T11:36:40-07:00</updated>
            <summary>
                <![CDATA[
                    Concept An Arduino Uno was used to run a sensor for collecting ambient temperature and humidty readings as well. This data was also output to a serial port that fed into a laptop. Hardware Process Resuts This sensor network developed for this project worked as&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p><strong>Concept</strong></p>
<figure class="post__image post__image--right"><img loading="lazy"  src="https://mattwilliams-ds.github.io/gh-page/media/posts/5/wireless_sensor_network.png" alt="" width="550" height="413" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/5/responsive/wireless_sensor_network-2xl.png 1920w"></figure>The purpose of this project was to develop a three node wireless sensor network with an end node, router, and coordinator. Soil moisture sensors were attached to the end node and router. The data flows from the end node to the router and then from the router to the coordinator. The coordinator would then write all data to a serial port where the laptop would listen and record the incoming data.</p>
<p>An Arduino Uno was used to run a sensor for collecting ambient temperature and humidty readings as well. This data was also output to a serial port that fed into a laptop.</p>
<p><strong>Hardware</strong></p>
<ol>
<li>DIGI XBee3 Zigbee Radio Development Boards</li>
<li>Soil Moisture Sensors</li>
<li>Ardiuno Uno</li>
<li>DHT11 Temperature &amp; Humidity Sensor</li>
</ol>
<p><strong>Process</strong></p>
<ol>
<li>Develop <strong>MicroPython</strong> scripts to establish communication &amp; run sensor data collection on the XBee3 radios.</li>
<li>Develop an <strong>Arduino</strong> script to collect ambient temperature &amp; humidity readings.</li>
<li>Develop a <strong>Python</strong> program that listens to local laptop ports for incoming data from the XBee3 coordinator and the Arduino Uno.</li>
<li>Record all data on the laptop to a CSV file for post processing.</li>
</ol>
<p><strong>Resuts</strong></p>
<p>This sensor network developed for this project worked as intended. Using try/except clauses I was able to make the network self-healing. Whenever a node dropped off the network, it would restart the communication protocol to locate the node it is supposed to report to. The MicroPython, Arduino, nd serial listening scripts are available on Github here. Also, check out a demonstration of the network below.</p>
<figure class="post__video"><iframe loading="lazy" width="560" height="314" src="https://www.youtube.com/embed/Yaj0-c3g5m0" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></figure>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Exoplanets &amp; Space Telescopes</title>
        <author>
            <name>Matt Williams</name>
        </author>
        <link href="https://mattwilliams-ds.github.io/gh-page/exoplanets-and-space-telescopes/"/>
        <id>https://mattwilliams-ds.github.io/gh-page/exoplanets-and-space-telescopes/</id>
            <category term="Projects"/>

        <updated>2025-01-01T08:03:59-07:00</updated>
            <summary>
                <![CDATA[
                    Concept This was an exploratory project that sought to synthesize the search for exoplanets by looking at the planets discovered, their size, and their distance from earth as well as the telescope facilities used to search for exoplanets. The project involves performing statistical analyses on&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p><strong>Concept</strong></p>
<p>This was an exploratory project that sought to synthesize the search for exoplanets by looking at the planets discovered, their size, and their distance from earth as well as the telescope facilities used to search for exoplanets. The project involves performing statistical analyses on the planet data as well as using regular expressions to process text descriptions of the telescopes to discern their size.</p>
<p><strong>Data</strong></p>
<ul>
<li>Nasa's <a href="https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&amp;config=PS" title="Nasa Exoplanet Archive" target="_blank" rel="noopener noreferrer">Exoplanet Archive</a></li>
</ul>
<p><strong>Process</strong></p>
<ol>
<li>Clean &amp; prepare data in <strong>Python</strong> using <strong>pandas</strong>.</li>
<li>Create a histogram of exoplanet discoveries per year with <strong>Matplotlib</strong></li>
<li>Analyze discoveries by method and discoveries by telescope.</li>
<li>Use <strong>RegEx</strong> expression on telescope descriptions to discern the smallest &amp; largest telescopes.</li>
<li>Create scatter plot of planet size by year discovered.</li>
<li>Visualize planet distance from earth by year discovered.</li>
</ol>
<p><strong>Results</strong></p>
<p>Through the course of this project, I found that the Kepler telescope is responsible for the vast majority of exoplanet discoveries. K2 is a second deployment of the Kepler telescope, making it the most productive facility.</p>
<figure class="post__image post__image--center"><img loading="lazy"  src="https://mattwilliams-ds.github.io/gh-page/media/posts/4/telescopes.png" alt="Exoplanet Discoveries by Facility" width="650" height="357" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/4/responsive/telescopes-2xl.png 1920w"></figure>
<p>The telescopes used to look for exoplanets have a staggaring range of focal lengths with the smallest being the KELT 80mm telescope and the largest being the 305m Arecibo telescope (no longer in service).</p>
<p>Check out the entire project in my <a href="https://www.kaggle.com/code/mattwilliamsds/the-search-for-exoplanets" title="exoplanet notebook" target="_blank" rel="noopener noreferrer">kaggle notebook</a>.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Assessing Homebuyer&#x27;s Risk</title>
        <author>
            <name>Matt Williams</name>
        </author>
        <link href="https://mattwilliams-ds.github.io/gh-page/assessing-homebuyers-risk/"/>
        <id>https://mattwilliams-ds.github.io/gh-page/assessing-homebuyers-risk/</id>
            <category term="Projects"/>

        <updated>2024-12-31T15:43:33-07:00</updated>
            <summary>
                <![CDATA[
                    A web application for evaluating property risks in Boulder County, Colorado. Concept The web map, created with ESRI's ArcGIS Web Application, allows homebuyers and residents to locate a property and see nearby risks including fracking wells, FEMA flood zones, Metro taxing district boundaries, as well&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>A web application for evaluating property risks in Boulder County, Colorado.</p>
<p><strong>Concept</strong></p>
<figure class="post__image post__image--right"><img loading="lazy"  src="https://mattwilliams-ds.github.io/gh-page/media/posts/3/webapp-2.png" alt="" width="450" height="356" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://mattwilliams-ds.github.io/gh-page/media/posts/3/responsive/webapp-2-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/3/responsive/webapp-2-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/3/responsive/webapp-2-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/3/responsive/webapp-2-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/3/responsive/webapp-2-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/3/responsive/webapp-2-2xl.png 1920w"></figure>There are a lot of tools for assessing a homes proximity to schools, community ammenities, parks, and more. What is harder to come by are tools for assessing potential risks to a home you may wish to purchase. This project seeks to solve that problem for Boulder County, Colorado.</p>
<p>The web map, created with ESRI's ArcGIS Web Application, allows homebuyers and residents to locate a property and see nearby risks including fracking wells, FEMA flood zones, Metro taxing district boundaries, as well as wildfire risk. Users of the application can then gauge their own cofort level with the proximity to these risk factors.</p>
<p><strong>Data</strong></p>
<ol>
<li>Fracking well locations and current status from <a href="https://www.fractracker.org/" target="_blank" rel="noopener noreferrer">FracTracker Alliance</a></li>
<li><a href="https://geo.colorado.edu/catalog/47540-5ca228ffd43267000b8c7448" target="_blank" rel="noopener noreferrer">FEMA 100 Year Flood Plain</a> </li>
<li><a href="https://geodata.colorado.gov/datasets/COOIT::metropolitan-districts/explore" target="_blank" rel="noopener noreferrer">Metropolitan Districts of Colorado</a></li>
<li>Wildfire Hazard Potential <a href="https://www.fs.usda.gov/rds/archive/catalog/RDS-2015-0047-4">Raster Data</a></li>
</ol>
<p><strong>Process</strong></p>
<ol>
<li>Clean fracking well data using <strong>Python</strong> &amp; <strong>Geopandas</strong></li>
<li>Reduce fracking well data, flood plain polygons, metro districts, and wildfire raster to only those in Boulder County using <strong>ArcGIS Pro</strong>.</li>
<li>Create 1/2 mile buffers around fracking wells and flood zones to provide  an omnidirectional sense of distance.</li>
<li>Upload everything to ESRI's <strong>ArcGIS Web Application</strong> service and create the map layout.</li>
<li>Color code fracking wells by their current status (active, plugged, abandoned, ...)</li>
</ol>
<p><strong>Results</strong></p>
<p>The final product was an ArcGIS Web Application hosted at ESRI.  Access the web application, <a href="https://ums.maps.arcgis.com/apps/webappviewer/index.html?id=fbd9b3af41264143aa576135ac56e41e" title="ArcGIS Web Application" target="_blank" rel="noopener noreferrer">here</a>.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Air Quality in Colorado</title>
        <author>
            <name>Matt Williams</name>
        </author>
        <link href="https://mattwilliams-ds.github.io/gh-page/air-quality-in-colorado/"/>
        <id>https://mattwilliams-ds.github.io/gh-page/air-quality-in-colorado/</id>
            <category term="Projects"/>

        <updated>2024-12-31T07:50:44-07:00</updated>
            <summary>
                <![CDATA[
                    Concept This project sought to shed light on how air quality varies in Colorado over space and time. The goal was to perform statistical and machine learning analyses on air quality data from both mountainous regions and what we locally call the "Front Range" which&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p><strong>Concept</strong></p>
<p>This project sought to shed light on how air quality varies in Colorado over space and time. The goal was to perform statistical and machine learning analyses on air quality data from both mountainous regions and what we locally call the "Front Range" which is the urban region on the east foothills of the Rocky Mountains.</p>
<p>Unfortunately, the only air quality monitor in the mountains was only active for a few years and was only intermitently functional when it was active.  Thus, the project pivotted to understanding how the Front Range air quality varies throughout the year.</p>
<p><strong>Data</strong></p>
<p>The dataset used for this project included 6 hour mean &amp; max particle measurements and 6 hour Air Quality Index (AQI) values for four air pollutants including nitrogen dioxide, carbon monoxide, sulfur dioxide, and ozone. There were 35,000 observations from Colorado taken at three different locations.</p>
<p><strong>Process</strong></p>
<p>Using <strong>R</strong>, the following process was used to understand the relationship of the pollutants to one another and how they vary with time:</p>
<ol>
<li>Clean data by removing observations from outside of Colorado.</li>
<li>Perform a correlation analysis using the "pairs" function in the praznik library to see how the pollutants relate to one another.</li>
<li>Factor records by county, AQI readings as either high or low based on guidance from Airnow.gov, and the season based on when the readings were taken.</li>
<li>Use the apriori library to discern association rules. The resulting rules show when each pollutant is generally high or low throughout the year.</li>
<li>Use the silhouette method to determine best number of clusters (2 in this case) for performing a k-means clustering analysis.<figure class="post__image post__image--center"><img loading="lazy"  src="https://mattwilliams-ds.github.io/gh-page/media/posts/2/adamsSilhouette.png" alt="" width="300" height="214" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsSilhouette-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsSilhouette-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsSilhouette-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsSilhouette-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsSilhouette-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsSilhouette-2xl.png 1920w"></figure></li>
<li>Perform k-means clustering on AQI values for each day of observations in the dataset</li>
<li>Count the number of times each cluster occurs by month.</li>
</ol>
<p><strong>Results</strong></p>
<p>The three analyses performed each confirmed the relationships of the pollutants to one another and through time through triangulation. This project illustrated the relationship between ozone, nitrogen dioxide, and temperature. More specifically, it shows that ozone is highest in the summer when the ambient temperatures are highest and when ozone is high, nitrogen dioxide is generally low. This makes sense given that ozone is created by the combination of nitrogen dioxide, heat, and volatile organic compounds.</p>
<p>Cluster breakdown by mean pollutant value in Adam's County, Colorado (highlighting indicating defining pollutant levels by cluster):</p>
<figure class="post__image post__image--center"><img loading="lazy"  src="https://mattwilliams-ds.github.io/gh-page/media/posts/2/adams_cluster_values.png" alt="" width="372" height="147" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adams_cluster_values-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adams_cluster_values-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adams_cluster_values-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adams_cluster_values-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adams_cluster_values-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adams_cluster_values-2xl.png 1920w"></figure>
<p>Cluster distribution in Adam's County by month:</p>
<figure class="post__image post__image--center"><img loading="lazy"  src="https://mattwilliams-ds.github.io/gh-page/media/posts/2/adamsClusters2.png" alt="" width="810" height="458" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsClusters2-xs.png 640w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsClusters2-sm.png 768w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsClusters2-md.png 1024w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsClusters2-lg.png 1366w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsClusters2-xl.png 1600w ,https://mattwilliams-ds.github.io/gh-page/media/posts/2/responsive/adamsClusters2-2xl.png 1920w"></figure>
<p>The mean pollutant values show that ozone is highest in cluster 1, when nitrogen dioxide is low. The distribution plot shows cluster 1 making up the majority of days during summer months. Then in winter, cluster 2 becomes dominant. Thus, ozone is highest in the summer when it gets hotter. When it temperatures cool off ozone levels go down and nitrogen dioxide levels are higher.</p>
            ]]>
        </content>
    </entry>
</feed>
